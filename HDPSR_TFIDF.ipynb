{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "print('All libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_descriptions = pd.read_csv('D:/_Barq/HDPSR/product_descriptions.csv')\n",
    "descriptions = product_descriptions.product_description\n",
    "\n",
    "# Split joint capital character words\n",
    "descriptions = [re.sub(r'([a-z])([A-Z])',r'\\1 \\2',description) \n",
    "                for description in descriptions]\n",
    "# Remove some unnecessary chars\n",
    "all_terms = (re.findall('([a-z]+)', description.lower()) for description in descriptions)\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in at from or on with '\n",
    "                'be am is are was were '\n",
    "                'it he she they you we ' \n",
    "                'will would should shall may might must '\n",
    "                'do does ' \n",
    "                'my her his them our us '\n",
    "                'mine hers his yours theirs its '\n",
    "                'not only also which that this these those '\n",
    "                '1 2 3 4 5 6 7 8 9 0 '\n",
    "                'a b c d e f g h i j k l m n o p q r s t u v w x y z xx'\n",
    "                'where when who why'.split())\n",
    "\n",
    "terms = [[term for term in all_term if term not in stoplist] \n",
    "        for all_term in all_terms]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for term in terms:\n",
    "    for token in term:\n",
    "        frequency[token] += 1\n",
    "\n",
    "terms = [[token for token in term if frequency[token] > 1]\n",
    "          for term in terms]\n",
    "\n",
    "dictionary = corpora.Dictionary(terms)\n",
    "dictionary.save('D:/_Barq/HDPSR/Discription.dict') # store the dictionary, for future reference\n",
    "\n",
    "corpus = [dictionary.doc2bow(term) for term in terms]\n",
    "corpora.MmCorpus.serialize('D:/_Barq/HDPSR/Discription.mm', corpus) # store to disk, for later use\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary and corpus were loaded.\n",
      "Tfidf model was made.\n",
      "Tfidf model was saved.\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load('D:/_Barq/HDPSR/Discription.dict')\n",
    "corpus = corpora.MmCorpus('D:/_Barq/HDPSR/Discription.mm')\n",
    "print('Dictionary and corpus were loaded.')\n",
    "\n",
    "Tfidf = models.TfidfModel(corpus)\n",
    "print('Tfidf model was made.')\n",
    "\n",
    "lsi.save('D:/_Barq/HDPSR/Discription.tfidf')\n",
    "print('Tfidf model was saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required data was loaded.\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166693.000000</td>\n",
       "      <td>166693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>123932.839741</td>\n",
       "      <td>2.145317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>71518.389174</td>\n",
       "      <td>0.253842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>61669.000000</td>\n",
       "      <td>2.046823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124004.000000</td>\n",
       "      <td>2.147283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>187036.000000</td>\n",
       "      <td>2.269176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>240760.000000</td>\n",
       "      <td>2.902156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      relevance\n",
       "count  166693.000000  166693.000000\n",
       "mean   123932.839741       2.145317\n",
       "std     71518.389174       0.253842\n",
       "min         1.000000       1.000000\n",
       "25%     61669.000000       2.046823\n",
       "50%    124004.000000       2.147283\n",
       "75%    187036.000000       2.269176\n",
       "max    240760.000000       2.902156"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('D:/_Barq/HDPSR/test.csv',sep=\",\", encoding=\"ISO-8859-1\")\n",
    "Tfidf = models.TfidfModel.load('D:/_Barq/HDPSR/Discription.Tfidf')\n",
    "corpus = corpora.MmCorpus('D:/_Barq/HDPSR/Discription.mm')\n",
    "dictionary = corpora.Dictionary.load('D:/_Barq/HDPSR/Discription.dict')\n",
    "print('All required data was loaded.')\n",
    "\n",
    "ident = []\n",
    "relev = []\n",
    "\n",
    "for idx, search_term in enumerate(test.search_term):\n",
    "    test_vec = (Tfidf[dictionary.doc2bow(search_term.lower().split())])\n",
    "    doc_vec = (Tfidf[corpus[test.product_uid[idx]-100001]])\n",
    "    ident.extend([test.id[idx]])\n",
    "    if (test_vec and doc_vec):\n",
    "        relev.extend([2+matutils.cossim(doc_vec, test_vec)])\n",
    "    else:\n",
    "        relev.extend([1])\n",
    "    if not idx%20000: \n",
    "        print(idx)\n",
    "    \n",
    "df = pd.DataFrame({'id': ident, 'relevance': relev})\n",
    "df.to_csv('D:/_Barq/HDPSR/MyPred_TFIDF_Description.csv',index=False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
